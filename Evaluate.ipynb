{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69b7c099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33357cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from datasetsforecast.long_horizon import LongHorizon\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Optional\n",
    "\n",
    "import os, pathlib\n",
    "from glob import glob\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from dataset import LongHorizonUnivariateDataModule, LongHorizonUnivariateDataset\n",
    "from dataset import ElectricityUnivariateDataModule, ElectricityUnivariateDataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "from utils.model_factory import instantiate\n",
    "\n",
    "from statsforecast.models import AutoETS, ETS, Theta, AutoCES\n",
    "\n",
    "from metrics import SMAPE, MAPE, CRPS\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='7'\n",
    "\n",
    "RESULTS_DIR = './results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74972642-ea67-4402-a291-18c6fc94e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6df882d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lightning_logs/test/MHLV/model=model.AnyQuantileForecaster-backbone=modules.NBEATSAQFILM-history=168-lr=0.0005-width=1024-layers=3-blocks=30-warmup=400-maxnorm=False-loss=losses.MQNLoss-seed=2/checkpoints/model-epoch=14.ckpt',\n",
       " 'lightning_logs/test/MHLV/model=model.AnyQuantileForecaster-backbone=modules.NBEATSAQFILM-history=168-lr=0.0005-width=1024-layers=3-blocks=30-warmup=400-maxnorm=False-loss=losses.MQNLoss-seed=6/checkpoints/model-epoch=14.ckpt',\n",
       " 'lightning_logs/test/MHLV/model=model.AnyQuantileForecaster-backbone=modules.NBEATSAQFILM-history=168-lr=0.0005-width=1024-layers=3-blocks=30-warmup=400-maxnorm=False-loss=losses.MQNLoss-seed=5/checkpoints/model-epoch=14.ckpt',\n",
       " 'lightning_logs/test/MHLV/model=model.AnyQuantileForecaster-backbone=modules.NBEATSAQFILM-history=168-lr=0.0005-width=1024-layers=3-blocks=30-warmup=400-maxnorm=False-loss=losses.MQNLoss-seed=1/checkpoints/model-epoch=14.ckpt',\n",
       " 'lightning_logs/test/MHLV/model=model.AnyQuantileForecaster-backbone=modules.NBEATSAQFILM-history=168-lr=0.0005-width=1024-layers=3-blocks=30-warmup=400-maxnorm=False-loss=losses.MQNLoss-seed=3/checkpoints/model-epoch=14.ckpt',\n",
       " 'lightning_logs/test/MHLV/model=model.AnyQuantileForecaster-backbone=modules.NBEATSAQFILM-history=168-lr=0.0005-width=1024-layers=3-blocks=30-warmup=400-maxnorm=False-loss=losses.MQNLoss-seed=7/checkpoints/model-epoch=14.ckpt',\n",
       " 'lightning_logs/test/MHLV/model=model.AnyQuantileForecaster-backbone=modules.NBEATSAQFILM-history=168-lr=0.0005-width=1024-layers=3-blocks=30-warmup=400-maxnorm=False-loss=losses.MQNLoss-seed=0/checkpoints/model-epoch=14.ckpt',\n",
       " 'lightning_logs/test/MHLV/model=model.AnyQuantileForecaster-backbone=modules.NBEATSAQFILM-history=168-lr=0.0005-width=1024-layers=3-blocks=30-warmup=400-maxnorm=False-loss=losses.MQNLoss-seed=4/checkpoints/model-epoch=14.ckpt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_name = \"model-epoch=14.ckpt\"\n",
    "\n",
    "backbone = \"modules.NBEATSAQFILM\"\n",
    "# NBEATSAQFILM NBEATSAQCAT NBEATSAQOUT \"model-epoch=14.ckpt\"\n",
    "# AqFilmCnn AqCatCnn AqOutCnn \"model-epoch=19.ckpt\"\n",
    "# AqCatTransformer AqOutTransformer \"model-epoch=19.ckpt\"\n",
    "blocks = 30\n",
    "lr=0.0005\n",
    "width=1024\n",
    "layers=3\n",
    "blocks=30\n",
    "warmup=400\n",
    "train_q=1\n",
    "quantile_embed_num=100\n",
    "quantile_embed_dim=64\n",
    "maxnorm=False\n",
    "loss=\"MQNLoss\"\n",
    "seed=\"*\" \n",
    "\n",
    "if 'NBEATS' in backbone:\n",
    "    # if loss == \"MQNLoss\":\n",
    "    #     checkpoint_pattern = f\"lightning_logs/new/MHLV/model=model.AnyQuantileForecaster-backbone={backbone}-history=168-lr={lr}-width={width}-layers={layers}-blocks={blocks}-warmup={warmup}-train_q={train_q}-quantile_embed_num={quantile_embed_num}-quantile_embed_dim={quantile_embed_dim}-maxnorm={maxnorm}-loss=losses.{loss}-seed={seed}/checkpoints/{checkpoint_name}\"\n",
    "    # else:\n",
    "    #     # checkpoint_pattern = f\"lightning_logs/new/MHLV/model=model.AnyQuantileForecaster-backbone={backbone}-history=168-lr={lr}-width={width}-layers={layers}-blocks={blocks}-warmup={warmup}-train_q={train_q}-quantile_embed_num={quantile_embed_num}-quantile_embed_dim={quantile_embed_dim}-maxnorm={maxnorm}-seed={seed}/checkpoints/{checkpoint_name}\"\n",
    "    checkpoint_pattern = f\"lightning_logs/test/MHLV/model=model.AnyQuantileForecaster-backbone={backbone}-history=168-lr={lr}-width={width}-layers={layers}-blocks={blocks}-warmup={warmup}-maxnorm={maxnorm}-loss=losses.{loss}-seed={seed}/checkpoints/{checkpoint_name}\"\n",
    "elif 'Cnn' in backbone:\n",
    "    if loss == \"MQNLoss\":\n",
    "        checkpoint_pattern = f\"lightning_logs/test/MHLV/model=model.GeneralAnyQuantileForecaster-backbone={backbone}-history=168-lr={lr}-width={width}-train_q={train_q}-quantile_embed_num={quantile_embed_num}-quantile_embed_dim={quantile_embed_dim}-maxnorm={maxnorm}-loss=losses.{loss}-seed={seed}/checkpoints/{checkpoint_name}\"\n",
    "    else:\n",
    "        checkpoint_pattern = f\"lightning_logs/test/MHLV/model=model.GeneralAnyQuantileForecaster-backbone={backbone}-history=168-lr={lr}-width={width}-train_q={train_q}-quantile_embed_num={quantile_embed_num}-quantile_embed_dim={quantile_embed_dim}-maxnorm={maxnorm}*-seed={seed}/checkpoints/{checkpoint_name}\"\n",
    "elif 'Transformer' in backbone:\n",
    "    # if loss == \"MQNLoss\":\n",
    "    checkpoint_pattern = f\"lightning_logs/test/MHLV/model=model.GeneralAnyQuantileForecaster-backbone={backbone}-history=168-lr={lr}-width={width}-blocks={blocks}-train_q={train_q}-quantile_embed_num={quantile_embed_num}-quantile_embed_dim={quantile_embed_dim}-maxnorm={maxnorm}-loss=losses.{loss}-seed={seed}/checkpoints/{checkpoint_name}\"\n",
    "    # else:\n",
    "    #     checkpoint_pattern = f\"lightning_logs/new/MHLV/model=model.GeneralAnyQuantileForecaster-backbone={backbone}-history=168-lr={lr}-width={width}-blocks={blocks}-train_q={train_q}-quantile_embed_num={quantile_embed_num}-quantile_embed_dim={quantile_embed_dim}-maxnorm={maxnorm}-seed={seed}/checkpoints/{checkpoint_name}\"\n",
    "\n",
    "model_list = glob(checkpoint_pattern)\n",
    "\n",
    "cfg = torch.load(model_list[0], map_location='cpu')['hyper_parameters']\n",
    "cfg = OmegaConf.create(cfg).cfg\n",
    "\n",
    "cfg.dataset.split_boundaries = ['2006-01-01', '2017-01-01', '2018-01-01', '2019-01-01']\n",
    "dm = instantiate(cfg.dataset)\n",
    "dm.setup(stage='test')\n",
    "test_loader = dm.test_dataloader()\n",
    "\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faed4ec9-947a-49d3-b461-60e4700031ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ckpt in tqdm(model_list):\n",
    "#     print(ckpt)\n",
    "#     model = torch.load(ckpt, map_location='cpu')\n",
    "#     model['hyper_parameters']['cfg']['model']['nn']['backbone']['_target_'] = 'modules.AqOutTransformer'\n",
    "#     torch.save(model, ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f72f5cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cf4df15fc34de1b5dc5593b5ed42e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfs = []\n",
    "for b in tqdm(test_loader):\n",
    "    df = pd.DataFrame.from_dict({k: list(v.cpu().numpy()) for k,v in b.items() if\n",
    "                                k in ['target', 'history', 'series_id', 'quantiles']})\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03755b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_random = 100\n",
    "num_deterministic = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44754fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c9a3e2787e406f9f0034b27eb73619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc745bd9e764aba998ad327e66ba059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be98284c10db458f81afd2bca4840d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd0397f10214fbe8567807edfda4ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bfc7a9bac324ab4b682ef5077a97640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35651afdb9d841bbb4b351f74182cbd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ddbf25fe9f343b9a70da4085d948259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [7]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23acc7737a984402a8ffc060425769d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_checkpoint(checkpoint_file, trainer):\n",
    "    cfg = torch.load(checkpoint_file)['hyper_parameters']\n",
    "    cfg = OmegaConf.create(cfg).cfg\n",
    "    \n",
    "    model = instantiate(cfg.model, cfg).load_from_checkpoint(checkpoint_file)\n",
    "\n",
    "    predictions = trainer.predict(model, dataloaders=dm.test_dataloader())\n",
    "    predictions = torch.cat(predictions).detach().cpu()\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "trainer = pl.Trainer(accelerator='gpu', devices=1)\n",
    "predictions = []\n",
    "for ckpt in model_list:\n",
    "    pred = predict_checkpoint(ckpt, trainer)\n",
    "    predictions.append(pred)\n",
    "    \n",
    "#     predictions_deterministic = pred[...,mid_idx-num_deterministic//2:mid_idx+num_deterministic//2+1]\n",
    "#     predictions_random = torch.cat([pred[..., 0:mid_idx-num_deterministic//2], \n",
    "#                                     pred[..., mid_idx+num_deterministic//2+1:]], dim=-1)\n",
    "#     predictions_random, _ = torch.sort(predictions_random, dim=-1)\n",
    "#     predictions_sort = torch.cat([predictions_deterministic, predictions_random], dim=-1)\n",
    "    \n",
    "#     predictions.append(predictions_sort)\n",
    "    \n",
    "predictions_ensemble = torch.stack(predictions).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86c0aaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7209e413cb5343d5914ba72c15a92231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRPS random quants 211.94969\n",
      "CRPS mandatory quants 209.80638\n"
     ]
    }
   ],
   "source": [
    "crps_rnd = CRPS()\n",
    "crps_fixed = CRPS()\n",
    "\n",
    "for target, pred, q in tqdm(zip(df.target, predictions_ensemble, df.quantiles), total=len(df)):\n",
    "    \n",
    "    if np.isinf(target).any():\n",
    "        continue\n",
    "\n",
    "    q_deterministic = q[:num_deterministic]\n",
    "    q_random = q[num_deterministic:]\n",
    "    # q_random = sorted(q_random)\n",
    "    \n",
    "    predictions_deterministic = pred[..., :num_deterministic]\n",
    "    predictions_random = pred[..., num_deterministic:]\n",
    "    # predictions_random = np.sort(predictions_random, axis=-1)\n",
    "    \n",
    "    crps_rnd.update(preds=torch.Tensor(predictions_random)[None], \n",
    "                target=torch.Tensor(target)[None], q=torch.Tensor(q_random)[None])\n",
    "    \n",
    "    crps_fixed.update(preds=torch.Tensor(predictions_deterministic)[None], \n",
    "                      target=torch.Tensor(target)[None], q=torch.Tensor(q_deterministic)[None])\n",
    "    \n",
    "print(\"CRPS random quants\", crps_rnd.compute().cpu().numpy())\n",
    "print(\"CRPS mandatory quants\", crps_fixed.compute().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9641c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76403f8fd2b49238ed0d801f607f04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RESULTS_PATH = f'results/MHLV/{backbone.split(\".\")[-1]}-maxnorm={maxnorm}-loss={loss}'\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "\n",
    "for worker in tqdm(range(len(predictions))):\n",
    "    p = predictions[worker]\n",
    "    for series_id in df.series_id.unique():\n",
    "        series_mask = df.series_id == series_id\n",
    "\n",
    "        df_series = df[series_mask]\n",
    "        p_series = p[series_mask.values].numpy()\n",
    "        \n",
    "        target_series = np.array([v for v in df.target[series_mask.values]])\n",
    "        target_series = np.nan_to_num(target_series, posinf=np.nan)\n",
    "        target_series = np.repeat(target_series[...,None], p.shape[-1], axis=-1)\n",
    "        \n",
    "        quantile_series = np.array([v for v in df.quantiles[series_mask.values]])\n",
    "        quantile_series = np.repeat(quantile_series[:,None], p.shape[1], axis=1)\n",
    "        \n",
    "        forec = pd.DataFrame({f\"forec{worker+1}\": p_series.ravel()})\n",
    "        if worker == 0:\n",
    "            forec['actuals'] = target_series.ravel()\n",
    "            forec['quants'] = quantile_series.ravel()\n",
    "            forec = forec[['actuals', 'quants', 'forec1']]\n",
    "        \n",
    "        forec.to_pickle(os.path.join(RESULTS_PATH, f'e1w{worker+1}_{series_id}.pickle'))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab0591-bd99-424d-a8be-92af86aad267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
